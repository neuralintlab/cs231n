{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from statistics import mode\n",
    "\n",
    "DATA_PATH = '/home/youngmin/Dataset/cifar-10-batches-py/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name):\n",
    "    with open(DATA_PATH + file_name, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='latin1')\n",
    "        \n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_cases_per_batch': 10000,\n",
       " 'label_names': ['airplane',\n",
       "  'automobile',\n",
       "  'bird',\n",
       "  'cat',\n",
       "  'deer',\n",
       "  'dog',\n",
       "  'frog',\n",
       "  'horse',\n",
       "  'ship',\n",
       "  'truck'],\n",
       " 'num_vis': 3072}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches_meta = load_data('batches.meta')\n",
    "batches_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "batch = load_data('data_batch_1')\n",
    "print(type(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of data for batch_label=<class 'str'>, len=21\n",
      "type of data for labels=<class 'list'>, len=10000\n",
      "type of data for data=<class 'numpy.ndarray'>, len=10000\n",
      "type of data for filenames=<class 'list'>, len=10000\n"
     ]
    }
   ],
   "source": [
    "for key, value in batch.items():\n",
    "    print(f'type of data for {key}={type(value)}, len={len(value)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training batch 1 of 5\n"
     ]
    }
   ],
   "source": [
    "print(batch['batch_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "# print unique labels and data type\n",
    "print(np.unique(batch['labels']))\n",
    "print(type(batch['labels'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3072)\n",
      "<class 'numpy.uint8'>\n",
      "min value in data = 0\n",
      "max value in data = 255\n"
     ]
    }
   ],
   "source": [
    "print(batch['data'].shape)\n",
    "print(type(batch['data'][0][0]))\n",
    "print('min value in data =', np.min(batch['data']))\n",
    "print('max value in data =', np.max(batch['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.hist(batch['data'].reshape(-1), bins=256)\n",
    "plt.title('Distribution of data value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check sample images and labels\n",
    "def show_sample(batch, idx):\n",
    "    # show image with a label\n",
    "    sample_image = np.swapaxes(batch['data'][idx].reshape(32, 32, 3, order='F'), 0, 1)\n",
    "    plt.figure()\n",
    "    plt.imshow(sample_image)\n",
    "    plt.title(batch['labels'][idx])\n",
    "    plt.show()\n",
    "\n",
    "    # show arrays\n",
    "    with np.printoptions(threshold=np.inf):\n",
    "        print('Red')\n",
    "        print(sample_image[:, :, 0])\n",
    "        print('Green')\n",
    "        print(sample_image[:, :, 1])\n",
    "        print('Blue')\n",
    "        print(sample_image[:, :, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red\n",
      "[[ 59  43  50  68  98 119 139 145 149 149 131 125 142 144 137 129 137 134\n",
      "  124 139 139 133 136 139 152 163 168 159 158 158 152 148]\n",
      " [ 16   0  18  51  88 120 128 127 126 116 106 101 105 113 109 112 119 109\n",
      "  105 125 127 122 131 124 121 131 132 133 133 123 119 122]\n",
      " [ 25  16  49  83 110 129 130 121 113 112 112 106 105 128 124 130 127 122\n",
      "  115 120 130 131 139 127 126 127 130 142 130 118 120 109]\n",
      " [ 33  38  87 106 115 117 114 105 107 121 125 109 113 146 133 127 118 117\n",
      "  127 122 132 137 136 131 124 130 132 135 130 125 121  94]\n",
      " [ 50  59 102 127 124 121 120 114 107 125 129 106 108 124 121 108  98 110\n",
      "  117 120 134 140 131 141 135 127 121 119 103  87  75  67]\n",
      " [ 71  84 110 129 136 131 129 119 108 122 123 105 107 111 108  98  94  97\n",
      "   83  88 102  97  88 118 140 136 120 107  88  67  35  32]\n",
      " [ 97 111 123 130 136 132 122 121 127 138 124 120 107  80  68  74 101 105\n",
      "   65  58  63  78 136 122 139 151 129 108  95  96  89  66]\n",
      " [115 119 130 140 133 127 138 137 131 133 134 108  72  51  41  72 181 209\n",
      "  125  68  64  82 123 112 135 151 137 114 105 101 126 102]\n",
      " [137 128 132 128 119 123 128 130 121 137 131  74  54  50  44  86 203 217\n",
      "  162 100  77  75  74  76 107 135 135 129 127 119 125 134]\n",
      " [154 154 156 140 123 125 126 127 133 132  90  63  62  70  79 103 152 148\n",
      "  141 121 101  96  86  75 101 136 136 134 133 132 128 133]\n",
      " [154 155 156 147 133 137 139 134 141 121  80  97  90  98 137 139 148 134\n",
      "  138 134 140 175 142 102 108 135 131 133 138 136 130 134]\n",
      " [145 146 146 135 127 129 117 103 130 120 111 146 136 163 169 152 161 148\n",
      "  177 161 195 209 189 125 108 140 137 132 136 133 132 133]\n",
      " [142 141 140 144 147 121  84  88 109 101 138 213 178 191 211 189 205 207\n",
      "  213 191 199 188 161 130 124 131 130 131 134 135 136 133]\n",
      " [158 154 142 143 132  90  72  81  84 107 165 229 183 191 239 219 228 225\n",
      "  214 216 210 200 189 174 161 139 134 126 131 142 136 138]\n",
      " [145 149 147 147 136  80  89 105  96 129 192 185 145 203 223 242 244 238\n",
      "  241 227 225 235 219 224 215 156 128 129 131 133 128 130]\n",
      " [148 146 145 147 133  63  66  88 113 182 220 138 162 206 196 247 255 255\n",
      "  245 236 230 215 231 250 241 158 125 126 124 125 126 124]\n",
      " [149 143 144 151 132  64  84 112 163 223 206 145 196 204 220 243 245 239\n",
      "  234 231 195 150 208 250 227 163 145 143 140 136 121 114]\n",
      " [147 134 140 148 135 100 108 144 210 248 175 175 220 226 230 233 224 201\n",
      "  184 181 190 170 179 231 223 162 146 140 139 145 142 128]\n",
      " [152 117 114 123 126 122  93 179 238 248 170 185 241 230 187 180 166 146\n",
      "  149 157 184 216 212 236 236 166 136 134 130 127 137 151]\n",
      " [145 127 128 133 132 135 171 237 252 229 173 169 220 194 123 135 127 151\n",
      "  165 132 151 202 240 240 222 156 119 120 112 100  99 140]\n",
      " [143 127 129 129 130 140 219 244 210 193 166 153 191 179 128 147 149 172\n",
      "  147 128 141 173 202 190 198 152 100 109 119 121 108 136]\n",
      " [143 125 131 128 123 153 148 166 188 182 171 165 195 190 152 143 152 153\n",
      "  142 141 135 136 148 141 141 138 111 111 121 129 138 179]\n",
      " [141 131 139 139 138 151 128 136 175 173 189 205 201 168 151 145 146 149\n",
      "  153 149 144 144 145 143 129 123 124 113 108 113 148 199]\n",
      " [143 139 138 149 160 150 147 151 169 167 179 212 203 207 149 139 144 137\n",
      "  151 155 152 140 107  91  84 105 132 118  96 102 159 190]\n",
      " [149 133 136 147 150 153 157 162 175 190 166 202 224 197 192 180 146 126\n",
      "  141 156 153 115  77  79  93 126 133 119 113 140 187 154]\n",
      " [172 144 135 136 135 139 153 163 166 184 166 150 184 156 158 168 149 135\n",
      "  130 132 128 127 135 143 139 136 127 121 135 189 211 136]\n",
      " [202 187 151 128 122 134 142 150 153 148 135 127 153 166 143 130 128 151\n",
      "  152 135 139 155 161 154 154 143 130 132 171 215 186 117]\n",
      " [216 193 168 151 131 126 138 144 142 137 120 131 145 144 137 127 126 139\n",
      "  153 149 140 135 147 148 149 149 137 143 203 206 124  71]\n",
      " [220 201 186 172 156 142 142 153 150 139 126 136 148 141 131 126 127 138\n",
      "  150 154 149 124 126 141 145 147 127 114 186 173  56  33]\n",
      " [208 201 198 191 183 171 159 147 135 130 139 147 144 145 137 136 137 148\n",
      "  152 150 155 138 120 128 142 135  90  50 137 160  56  53]\n",
      " [180 173 186 194 198 201 189 173 156 139 142 145 141 141 139 140 143 139\n",
      "  138 143 146 135 117 112 122 104  58  34 131 184  97  83]\n",
      " [177 168 179 188 202 218 218 207 191 175 166 163 163 161 153 159 162 149\n",
      "  140 148 161 144 112 119 130 120  92 103 170 216 151 123]]\n",
      "Green\n",
      "[[ 62  46  48  54  73  91 107 110 117 120 103  99 115 112 105  97 106 106\n",
      "   97 113 112 105 105 108 120 131 136 129 130 132 125 124]\n",
      " [ 20   0   8  27  51  82  89  86  87  79  70  67  70  74  70  72  79  71\n",
      "   69  89  92  85  89  82  79  89  91  94  96  88  83  87]\n",
      " [ 24   7  27  50  72  92  93  82  77  78  79  75  73  92  87  92  89  85\n",
      "   79  85  95  96 102  90  89  89  92 105  94  84  84  73]\n",
      " [ 25  20  54  63  70  74  72  62  68  84  90  75  77 105  91  84  76  76\n",
      "   87  81  92  99  99  93  86  91  90  93  90  87  85  62]\n",
      " [ 32  32  65  79  77  77  78  74  72  88  89  68  71  83  78  68  65  74\n",
      "   80  80  93 106  95  98  92  84  79  79  67  57  47  42]\n",
      " [ 48  53  73  82  88  84  84  77  70  82  81  65  72  77  74  65  62  63\n",
      "   56  58  68  69  54  74  96  97  80  68  54  39  10  13]\n",
      " [ 69  75  85  84  88  83  74  74  83  94  79  79  71  50  43  41  51  56\n",
      "   37  36  37  51  93  68  86 106  87  68  59  63  61  47]\n",
      " [ 82  76  90  97  88  81  90  89  86  89  91  70  39  26  22  31 102 127\n",
      "   76  40  38  53  77  56  81 103  95  76  69  66  92  74]\n",
      " [100  82  91  87  81  82  85  85  80  97  94  42  25  29  29  39 106 109\n",
      "   90  58  42  43  39  35  67  96  97  91  89  83  86  95]\n",
      " [120 112 114 100  89  86  86  91  97  97  60  35  33  39  50  53  70  64\n",
      "   79  75  58  54  48  38  63  91  92  93  93  93  86  92]\n",
      " [122 117 117 108 100 100 102 102 111  87  40  53  45  56  91  84  87  73\n",
      "   82  85  92 129  99  61  67  90  87  91  97  95  86  93]\n",
      " [114 109 109  97  92  94  84  74 103  83  60  86  78 116 115 100 116  97\n",
      "  121 110 150 167 146  78  63  96  95  93  95  90  87  92]\n",
      " [115 106 105 105 110  89  56  61  80  57  79 150 123 150 169 148 164 162\n",
      "  164 143 158 151 121  83  77  87  91  93  93  91  89  91]\n",
      " [131 119 107 102  92  59  44  52  47  55 106 176 137 158 216 192 188 188\n",
      "  177 174 171 169 162 137 118  95  96  90  92  98  89  97]\n",
      " [115 109 108 105  95  47  57  68  51  81 152 148 101 162 200 227 227 220\n",
      "  219 197 191 209 206 208 192 118  89  95  95  97  89  92]\n",
      " [116 100 100 100  96  42  43  50  65 146 191  94 105 156 166 234 253 252\n",
      "  234 217 208 196 217 241 229 132  95  97  92  91  88  88]\n",
      " [115  95  97  99  87  40  59  69 121 204 182  90 133 157 188 226 237 233\n",
      "  224 217 181 137 193 241 216 142 127 129 123 116  95  82]\n",
      " [111  88  99 103  89  64  73 104 181 243 147 119 176 197 207 218 212 186\n",
      "  163 158 171 157 167 218 206 133 116 115 116 123 119 102]\n",
      " [114  75  80  90  91  83  58 154 226 243 134 132 214 218 169 160 146 119\n",
      "  116 124 157 195 198 221 212 125  85  81  83  86 105 128]\n",
      " [105  82  90  92  89  95 145 227 247 213 136 121 182 169  89  98  91 114\n",
      "  127  99 126 183 228 225 196 117  76  75  66  65  74 121]\n",
      " [104  80  86  85  86 102 196 232 199 173 129 104 146 145  86 102 106 131\n",
      "  108  94 113 150 183 171 175 124  72  81  88  92  82 119]\n",
      " [104  76  85  81  81 117 118 141 166 156 134 115 148 153 108  95 105 110\n",
      "  102 102 101 101 110 106 111 113 100 111 118 116 116 162]\n",
      " [102  80  89  87  90 111  91  97 136 136 151 160 157 131 108  97 101 106\n",
      "  110 108 104 105 104 102  96 103 126 135 133 122 136 184]\n",
      " [103  87  89  96 109 106 104 104 121 123 141 174 168 177 112  96 102  94\n",
      "  107 111 109 101  76  60  61  99 142 141 121 113 149 174]\n",
      " [107  80  88  99 104 109 112 117 131 145 124 168 197 175 165 144 106  82\n",
      "   97 112 109  74  43  50  73 117 134 116  99 121 165 132]\n",
      " [128  88  85  88  90  94 108 117 120 136 118 110 149 121 123 130 109  91\n",
      "   85  88  84  83  92 105 108 112 105  92 102 159 181 107]\n",
      " [157 129 100  79  76  88  98 106 106  99  87  82 109 121  99  88  87 108\n",
      "  106  90  95 110 113 107 112 105  93  90 131 183 155  86]\n",
      " [174 136 122 111  88  82  94 100  95  92  78  87  99 101  94  83  82  94\n",
      "  108 104  95  91 103 105 108 109 101 107 167 173  93  48]\n",
      " [182 150 148 139 120 103 100 108 105  98  88  92 102 101  89  82  81  88\n",
      "  100 104 101  78  85 101 107 112 101  87 155 144  29  19]\n",
      " [170 153 161 157 146 135 121 107  95  87  93  98  95  99  91  89  90 102\n",
      "  106 103 110  94  76  84 102 103  69  24 105 133  31  34]\n",
      " [139 123 144 153 158 164 153 137 118  99  97  97  92  93  91  91  95  99\n",
      "   98  96  93  84  80  72  81  67  31   5  94 148  62  53]\n",
      " [144 129 142 149 168 189 191 181 163 143 132 128 127 123 114 120 124 116\n",
      "  104 103 105  95  90  91  96  87  67  78 140 184 118  92]]\n",
      "Blue\n",
      "[[ 63  45  43  42  52  63  75  80  89  93  77  76  91  86  79  71  79  76\n",
      "   64  78  75  69  74  77  89 100 108 102 104 108 102 103]\n",
      " [ 20   0   0   8  21  43  45  44  50  44  37  35  36  35  33  37  44  33\n",
      "   27  46  46  39  47  41  37  48  53  58  60  55  50  57]\n",
      " [ 21   0   8  23  41  54  55  47  43  44  46  45  38  48  47  56  56  51\n",
      "   43  47  54  55  62  51  49  50  53  68  58  50  50  42]\n",
      " [ 17   4  25  28  33  35  37  33  33  45  53  40  38  58  47  45  40  41\n",
      "   52  43  51  58  57  52  44  50  49  51  50  50  48  35]\n",
      " [ 21  11  34  39  36  36  40  39  34  49  51  31  33  42  39  29  23  37\n",
      "   49  41  50  66  58  66  51  45  41  40  32  27  23  25]\n",
      " [ 29  24  37  38  45  42  43  37  33  44  39  25  31  31  34  27  21  32\n",
      "   38  36  42  46  36  72  79  64  45  34  24  15   0   4]\n",
      " [ 40  36  43  38  44  40  30  31  46  54  34  39  34  14  17  17  21  23\n",
      "   16  19  18  31  83  80  79  69  49  36  29  37  38  30]\n",
      " [ 49  33  47  53  48  40  47  46  48  46  46  39  19  10  14  17  69  81\n",
      "   47  23  17  30  62  55  60  61  54  39  34  33  59  46]\n",
      " [ 68  41  51  48  44  43  44  44  40  54  53  20  16  16  18  15  56  62\n",
      "   71  49  27  24  24  22  36  59  58  49  48  43  45  56]\n",
      " [ 89  77  82  65  53  50  48  52  60  68  30   9  16  20  30  26  33  37\n",
      "   61  57  41  33  24  21  32  53  53  50  52  52  45  55]\n",
      " [ 94  82  82  70  64  66  68  66  81  68  13  17  17  30  57  49  54  37\n",
      "   46  57  76 106  53  26  25  41  45  51  57  55  46  57]\n",
      " [ 89  73  69  55  57  65  55  42  70  55  14  22  23  77  69  52  73  57\n",
      "   82  71 113 123  94  40  25  52  59  56  57  51  46  56]\n",
      " [ 86  69  68  64  74  65  34  33  44  23  19  59  41  98 122  99 110 115\n",
      "  118  91  97  88  76  50  38  51  61  60  57  52  48  56]\n",
      " [ 98  82  74  65  59  36  22  24  19  25  50  92  57 103 176 149 128 120\n",
      "  112 112 110 109 114 100  76  57  66  59  56  60  48  61]\n",
      " [ 79  66  68  65  62  21  32  40  26  45 113 107  51 121 170 196 186 165\n",
      "  163 144 139 157 164 181 156  78  57  62  60  60  50  56]\n",
      " [ 79  54  55  51  54  21  31  34  37 110 169  71  63 112 135 212 232 219\n",
      "  197 180 170 160 197 229 195  78  49  58  52  49  46  54]\n",
      " [ 79  49  51  51  49  21  41  37  75 166 157  56  84 110 156 208 226 215\n",
      "  201 192 152 100 154 216 173  78  60  62  55  46  30  40]\n",
      " [ 76  47  61  66  60  38  43  66 140 212 115  73 129 164 179 196 195 166\n",
      "  138 128 136 105 105 181 161  71  43  34  33  38  35  41]\n",
      " [ 80  37  48  57  56  48  32 138 212 229 104  88 177 195 142 131 115  85\n",
      "   79  83 110 141 152 197 176  63  16  13  13  16  27  54]\n",
      " [ 72  41  51  53  49  51 110 205 235 194 100  73 138 135  55  60  48  63\n",
      "   74  50  79 142 203 210 169  64  12  16  14  15  19  54]\n",
      " [ 66  38  49  46  45  59 161 210 186 151  92  55  96 105  47  58  59  78\n",
      "   54  45  67 112 160 147 146  86  26  34  43  50  36  50]\n",
      " [ 64  32  48  43  39  76  85 118 147 132  99  69  99 110  66  49  56  58\n",
      "   51  54  55  60  74  65  68  71  37  31  35  39  45  83]\n",
      " [ 65  35  46  44  50  71  52  61 104 107 118 120 113  89  65  53  52  57\n",
      "   61  61  59  59  59  60  48  39  30  14   8  10  44 102]\n",
      " [ 72  44  42  52  72  64  58  57  81  87 105 138 132 141  74  55  56  47\n",
      "   61  65  63  55  38  34  23  25  34  20   4   9  63  99]\n",
      " [ 74  37  48  59  63  62  67  78  96 107  84 133 168 148 133 107  64  40\n",
      "   52  66  61  29  14  25  33  47  39  31  24  42  91  75]\n",
      " [ 76  18  35  48  45  49  68  83  82 100  88  75 110  86  87  92  71  51\n",
      "   43  43  37  36  52  66  62  52  39  39  44  87 114  58]\n",
      " [ 82  26  25  34  41  49  53  56  58  63  59  44  60  77  59  51  52  70\n",
      "   65  48  50  63  65  63  67  54  44  46  70 106  91  48]\n",
      " [ 87  16  19  35  34  35  49  53  53  51  34  41  52  57  54  48  51  60\n",
      "   69  63  53  46  57  59  62  63  54  57 102 105  49  26]\n",
      " [ 91  22  24  28  26  30  51  75  73  57  38  47  62  60  51  49  51  52\n",
      "   60  65  60  36  41  55  61  68  59  46  98  87   9   9]\n",
      " [ 96  34  26  27  34  32  42  52  49  46  57  62  55  57  51  52  54  58\n",
      "   60  61  64  46  33  39  58  62  40  11  60  70   7  20]\n",
      " [ 96  42  30  25  34  36  32  32  38  38  49  56  52  52  51  53  58  60\n",
      "   60  56  43  33  38  29  39  30  11   0  57  94  34  34]\n",
      " [116  94  87  67  68  76  72  70  79  82  86  92  94  92  84  90  93  91\n",
      "   83  77  69  55  59  58  65  59  46  57 104 140  84  72]]\n"
     ]
    }
   ],
   "source": [
    "show_sample(batch, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data file tuple\n",
    "data_list_training = ('data_batch_1', 'data_batch_2', 'data_batch_3', 'data_batch_4', 'data_batch_5')\n",
    "data_test = 'test_batch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and check training data\n",
    "Xtr = []\n",
    "Ytr = []\n",
    "\n",
    "for batch_name in data_list_training:\n",
    "    batch = load_data(batch_name)\n",
    "    Xtr.append(batch['data'])\n",
    "    Ytr.append(batch['labels'])\n",
    "    \n",
    "Xtr = np.concatenate(Xtr)\n",
    "Ytr = np.concatenate(Ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072)\n",
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "print(Xtr.shape)\n",
    "print(Ytr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5000, 1: 5000, 2: 5000, 3: 5000, 4: 5000, 5: 5000, 6: 5000, 7: 5000, 8: 5000, 9: 5000}\n"
     ]
    }
   ],
   "source": [
    "labels, counts = np.unique(Ytr, return_counts=True)\n",
    "print({label:count for label, count in zip(labels, counts)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3072)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# load and check test data\n",
    "batch = load_data(data_test)\n",
    "Xte = batch['data']\n",
    "Yte = np.array(batch['labels'])\n",
    "print(Xte.shape)\n",
    "print(Yte.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Linear Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"cs231n_slide_001.png\" width=\"600\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our dimensions\n",
    "* a mini-batch of images, x: (batch_size, n_dim) = (batch_size, 3072)\n",
    "* weight matrix, W: (n_dim, n_class) = (3072, 10)\n",
    "* bias, b: (n_class) = (10)\n",
    "* output: np.dot(x, W) + b, shape = (batch_size, 3072) • (3072, 10) + (10) = (batch_size, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear classifer class\n",
    "class LinearClassifier(object):\n",
    "\n",
    "    # initialize parameters\n",
    "    def __init__(self, n_dim, n_class):\n",
    "        # n_dim = number of pixels in image (3072 in CIFAR-10 image)\n",
    "        # n_class = number of classes to classify (10 in CIFAR-10)\n",
    "        self.W = np.random.randn(n_dim, n_class)  # initial random weight: W.shape = (10, 3072)\n",
    "        self.b = np.zeros(n_class) # initial zero bias: b.shape = (10)\n",
    "\n",
    "    # forward-pass: giving softmax scores for each class\n",
    "    def forward(self, x): # x is a mini-batch of images: x.shape = (batch_size, n_dim)\n",
    "        return np.dot(x, self.W) + self.b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of W = (3072, 10)\n",
      "shape of b = (10,)\n"
     ]
    }
   ],
   "source": [
    "# make an instance of linear classifier\n",
    "n_dim = Xtr.shape[1]\n",
    "n_class = 10\n",
    "\n",
    "lc = LinearClassifier(n_dim, n_class)\n",
    "\n",
    "print('shape of W =', lc.W.shape)\n",
    "print('shape of b =', lc.b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data (run just once!)\n",
    "Xtr = (Xtr - 127.5) / 255\n",
    "Xte = (Xte - 127.5) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set\n",
      "global mean = -0.02664\n",
      "global std  = 0.25157\n",
      "global max = 0.50000\n",
      "global min = -0.50000\n",
      "\n",
      "Test set\n",
      "global mean = -0.02342\n",
      "global std  = 0.25122\n",
      "global max = 0.50000\n",
      "global min = -0.50000\n"
     ]
    }
   ],
   "source": [
    "# check normalized data\n",
    "print('Training set')\n",
    "print('global mean = %.5f' % np.mean(Xtr))\n",
    "print('global std  = %.5f' % np.std(Xtr))\n",
    "print('global max = %.5f' % np.max(Xtr))\n",
    "print('global min = %.5f' % np.min(Xtr))\n",
    "\n",
    "print()\n",
    "print('Test set')\n",
    "print('global mean = %.5f' % np.mean(Xte))\n",
    "print('global std  = %.5f' % np.std(Xte))\n",
    "print('global max = %.5f' % np.max(Xte))\n",
    "print('global min = %.5f' % np.min(Xte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of mini batch = (4, 3072)\n"
     ]
    }
   ],
   "source": [
    "# sample mini-batch\n",
    "mini_batch = Xtr[:4, :] # the first 4 images from training set\n",
    "print('shape of mini batch =', mini_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of output = (4, 10)\n",
      "[[  6.19753789 -14.62859206 -11.00103395  11.23478537 -18.97158335\n",
      "    7.78850014  14.76150544   2.79917452  15.21169334  -6.01630106]\n",
      " [ 26.94257572   2.00412335  11.49018554   0.77082373  -1.88651534\n",
      "    1.98858418  -3.80694921  -2.61440709  15.75523734  -9.33087724]\n",
      " [ 14.42723586  -7.9025127    9.41526175  17.135364     7.29097973\n",
      "  -15.48421154  -1.54725159   8.39991433 -21.91234378  -2.39185283]\n",
      " [  1.65946135 -10.79406384   8.23771669  12.1803299   -5.3701786\n",
      "   26.45854312  -0.31081592  -6.72476082   4.31732147  -0.05013305]]\n"
     ]
    }
   ],
   "source": [
    "# output\n",
    "output = lc.forward(mini_batch)\n",
    "print('shape of output =', output.shape) # each row assigns 10 numbers \n",
    "print(output)\n",
    "\n",
    "# output - np.max(output, axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.37568628, 41.31278097,  7.43058323, 29.60342032])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax function (raw ver)\n",
    "def softmax(y): # input y is output of the model y = xW + b\n",
    "    denominator = np.sum(np.exp(y), axis=1)[:, np.newaxis]\n",
    "    return np.exp(y) / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.34321283e-05, 6.62541060e-14, 2.49253500e-12, 1.13118828e-02,\n",
       "        8.61143728e-16, 3.60439386e-04, 3.84742326e-01, 2.45468434e-06,\n",
       "        6.03509465e-01, 3.64320201e-10],\n",
       "       [9.99985957e-01, 1.47693591e-11, 1.94583547e-07, 4.30275315e-12,\n",
       "        3.01771858e-13, 1.45416294e-11, 4.42226645e-14, 1.45733491e-13,\n",
       "        1.38482399e-05, 1.76454785e-16],\n",
       "       [6.24569254e-02, 1.25283541e-11, 4.15822420e-04, 9.36926901e-01,\n",
       "        4.96985759e-05, 6.38563438e-15, 7.21022552e-09, 1.50642710e-04,\n",
       "        1.03157709e-17, 3.09844071e-09],\n",
       "       [1.69783449e-11, 6.62823783e-17, 1.22122405e-08, 6.29579399e-07,\n",
       "        1.50300876e-14, 9.99999358e-01, 2.36709019e-12, 3.87859050e-15,\n",
       "        2.42208475e-10, 3.07204757e-12]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# too big or small numbers may cause numerical unstability\n",
    "softmax(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(output).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax function (stable ver)\n",
    "def softmax(y): # input y is output of the model y = xW + b\n",
    "    y = y - np.max(y, axis=1)[:, np.newaxis] # maximum output would be 0, np.exp(max) = 1\n",
    "    denominator = np.sum(np.exp(y), axis=1)[:, np.newaxis]\n",
    "    return np.exp(y) / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.34321283e-05, 6.62541060e-14, 2.49253500e-12, 1.13118828e-02,\n",
       "        8.61143728e-16, 3.60439386e-04, 3.84742326e-01, 2.45468434e-06,\n",
       "        6.03509465e-01, 3.64320201e-10],\n",
       "       [9.99985957e-01, 1.47693591e-11, 1.94583547e-07, 4.30275315e-12,\n",
       "        3.01771858e-13, 1.45416294e-11, 4.42226645e-14, 1.45733491e-13,\n",
       "        1.38482399e-05, 1.76454785e-16],\n",
       "       [6.24569254e-02, 1.25283541e-11, 4.15822420e-04, 9.36926901e-01,\n",
       "        4.96985759e-05, 6.38563438e-15, 7.21022552e-09, 1.50642710e-04,\n",
       "        1.03157709e-17, 3.09844071e-09],\n",
       "       [1.69783449e-11, 6.62823783e-17, 1.22122405e-08, 6.29579399e-07,\n",
       "        1.50300876e-14, 9.99999358e-01, 2.36709019e-12, 3.87859050e-15,\n",
       "        2.42208475e-10, 3.07204757e-12]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear classifer class with softmax output\n",
    "class LinearClassifier(object):\n",
    "\n",
    "    # initialize parameters\n",
    "    def __init__(self, n_dim, n_class):\n",
    "        # n_dim = number of pixels in image (3072 in CIFAR-10 image)\n",
    "        # n_class = number of classes to classify (10 in CIFAR-10)\n",
    "        self.W = np.random.randn(n_dim, n_class)  # initial random weight: W.shape = (10, 3072)\n",
    "        self.b = np.zeros(n_class) # initial zero bias: b.shape = (10)\n",
    "\n",
    "    # forward-pass: giving softmax scores for each class\n",
    "    def forward(self, x): # x is a mini-batch of images: x.shape = (batch_size, n_dim)\n",
    "        y = np.dot(x, self.W) + self.b\n",
    "        return softmax(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of W = (3072, 10)\n",
      "shape of b = (10,)\n"
     ]
    }
   ],
   "source": [
    "# make an instance of linear classifier\n",
    "n_dim = Xtr.shape[1]\n",
    "n_class = 10\n",
    "\n",
    "lc = LinearClassifier(n_dim, n_class)\n",
    "\n",
    "print('shape of W =', lc.W.shape)\n",
    "print('shape of b =', lc.b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of output = (4, 10)\n",
      "[[2.13230912e-11 9.15327746e-02 1.65475448e-03 1.64295128e-10\n",
      "  1.53520015e-11 4.48767675e-15 9.06805907e-01 4.19364151e-19\n",
      "  8.67494023e-07 5.69596122e-06]\n",
      " [8.36758999e-09 1.07390425e-02 9.89015526e-01 3.12059184e-13\n",
      "  9.49224146e-12 3.53558554e-07 2.25365333e-04 1.96642461e-05\n",
      "  4.00822305e-08 2.08274052e-13]\n",
      " [8.09147962e-23 5.15929474e-08 4.52641549e-04 9.99547307e-01\n",
      "  9.14211527e-19 7.94554433e-29 3.15425697e-37 1.85335878e-33\n",
      "  3.99342438e-26 1.66260300e-10]\n",
      " [2.22042315e-08 9.49101465e-08 9.85293522e-01 2.71384265e-07\n",
      "  3.80657265e-14 3.02058740e-16 1.47060694e-02 1.77777943e-20\n",
      "  1.93437763e-08 8.95743497e-10]]\n"
     ]
    }
   ],
   "source": [
    "# output\n",
    "output = lc.forward(mini_batch)\n",
    "print('shape of output =', output.shape) # each row assigns 10 numbers \n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 9, 4, 1, 1, 2, 7, 8, 3])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytr[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoder\n",
    "def onehot(y, n_class):\n",
    "    vectors = np.zeros((len(y), n_class))\n",
    "    for i, label in enumerate(y):\n",
    "        vectors[i, label] = 1\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot(Ytr[:10], n_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-entropy loss\n",
    "def loss(y_true, y_pred):\n",
    "    return np.sum(-y_true * np.log(y_pred), axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.09782685, 29.19992162, 22.51746648, 30.89946208])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(onehot(Ytr[:4], n_class), output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 9, 4])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# true labels\n",
    "Ytr[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 2, 3, 2])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model prediction\n",
    "np.argmax(output, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-entropy loss to give a single number\n",
    "def loss(y_true, y_pred):\n",
    "    return np.mean(np.sum(-y_true * np.log(y_pred), axis=1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.678669259870297"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(onehot(Ytr[:4], n_class), output) # mean of 4 losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss = 21.45921\n"
     ]
    }
   ],
   "source": [
    "# calculate loss for the entire test set\n",
    "y_pred = lc.forward(Xte)\n",
    "y_true = onehot(Yte, n_class)\n",
    "test_loss = loss(y_true, y_pred)\n",
    "print('Test loss = %.5f' % test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d1a104cc5a30ffb61dcba35c048d59e2a2543d3b82917e7c4c5fa986c3cfbc1d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.11 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
